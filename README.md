# Vision Language Learning (VLL)
In this repository, we list the publications related to vision-language learning, including image-text embedding, image captioning, text-based image generation, visual quastion answering and VL pre-training.
## Image-text Embedding
### 2021
### 2020
### 2019
## Image Captioning
### 2021
### 2020
### 2019 
1. [Hossain, MD Zakir and Sohel, Ferdous and Shiratuddin, Mohd Fairuz and Laga, Hamid. A comprehensive survey of deep learning for image captioning.
ACM Computing Surveys (CSUR), 2019.](https://dl.acm.org/doi/abs/10.1145/3295748?casa_token=yC0B4ul8CVAAAAAA:y3QIHQS-Xg26IA6hAvSySU_XCKgVfH-OyE_2ejRczBsheExFjM94ApfsiZ7ME6aB8k3tXUT3JfwOL4M)
### 2018
1. [Jiuxiang Gu, Jianfei Cai, Gang Wang, Tsuhan Chen. Stack-Captioning: Coarse-to-Fine Learning for Image Captioning. AAAI, 2018.](https://ojs.aaai.org/index.php/AAAI/article/view/12266)
2. [Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei. Bottom-up and top-down attention for image captioning and visual question answering. CVPR, 2018.](https://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html)
3. [Gu, Jiuxiang and Joty, Shafiq and Cai, Jianfei and Wang, Gang. Unpaired image captioning by language pivoting. ECCV, 2018.](https://openaccess.thecvf.com/content_ECCV_2018/html/Jiuxiang_Gu_Unpaired_Image_Captioning_ECCV_2018_paper.html)
### 2017
1. [Lu, Jiasen and Xiong, Caiming and Parikh, Devi and Socher, Richard. Knowing when to look: Adaptive attention via a visual sentinel for image captioning. CVPR, 2017.](https://openaccess.thecvf.com/content_cvpr_2017/html/Lu_Knowing_When_to_CVPR_2017_paper.html)
## Text-based Image Generation
### 2021
### 2020
### 2019
## Visual Question Answering
## Pre-training
